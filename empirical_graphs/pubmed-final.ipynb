{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, action_features, structural_features, labels, idx_train, idx_test, idx_val = load_data('pubmed')\n",
    "if torch.cuda.is_available():\n",
    "    action_features = action_features.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "untrained_accs, untrained_accs_sd = run_model_within(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=0,\n",
    "    n_neg_samples_shuffle=20,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=0,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(untrained_accs), np.std(untrained_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_accs, shuffle_accs_sd = run_model_within(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=0,\n",
    "    n_neg_samples_shuffle=20,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(shuffle_accs), np.std(shuffle_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_shuffle_accs, no_shuffle_accs_sd = run_model_within(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=20,\n",
    "    n_neg_samples_shuffle=0,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(no_shuffle_accs), np.std(no_shuffle_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_accs, within_accs_sd = run_model_within(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=10,\n",
    "    n_neg_samples_shuffle=10,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(within_accs), np.std(within_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_accs, between_accs_sd = run_model_between(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=20,\n",
    "    n_neg_samples_shuffle=0,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.mean(between_accs), np.std(between_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_accs, both_accs_sd = run_model_both(\n",
    "    model_class=MeanModel,\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    n_pos_samples=5,\n",
    "    n_neg_samples_rand=10,\n",
    "    n_neg_samples_shuffle=10,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    labels=labels,\n",
    "    train_idx_list=idx_train,\n",
    "    test_idx_list=idx_test,\n",
    "    lr=0.01,\n",
    "    n_epochs=200,\n",
    "    batch_size=256,\n",
    "    dropout=0.6,\n",
    "    n_runs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(both_accs), np.std(both_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [x for x in g.node]\n",
    "n_pos_samples = 5\n",
    "n_neg_samples_rand = 10\n",
    "n_neg_samples_shuffle = 10\n",
    "lr = 0.01\n",
    "\n",
    "model1 = MeanModel(\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    dropout=0.6,\n",
    ")\n",
    "optimizer1 = optim.Adam(\n",
    "    model1.parameters(),\n",
    "    lr=lr,\n",
    ")\n",
    "model2 = MeanModel(\n",
    "    emb_dim=64,\n",
    "    hidden_dim=192,\n",
    "    n_nbr_samples1=25,\n",
    "    n_nbr_samples2=10,\n",
    "    g=g,\n",
    "    features=action_features,\n",
    "    dropout=0.6,\n",
    ")\n",
    "model2 = model1\n",
    "optimizer2 = optim.Adam(\n",
    "    model2.parameters(),\n",
    "    lr=lr,\n",
    ")\n",
    "total_loss = 0\n",
    "for epoch in range(200):\n",
    "    model1 = model1.train()\n",
    "    model2 = model2.train()\n",
    "    random.shuffle(node_list)\n",
    "    batch = node_list[:256]\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    emb_u = model1(batch)\n",
    "    nbrs = []\n",
    "    for node in batch:\n",
    "        for _ in range(n_pos_samples):\n",
    "            nbrs.append(node)\n",
    "    emb_v = model2(nbrs).view(n_pos_samples * len(batch), -1)\n",
    "    neg_nodes_shuffle = []\n",
    "    neg_nodes_rand = []\n",
    "    for idx, node in enumerate(batch):\n",
    "        for _ in range(n_neg_samples_shuffle):\n",
    "            neg_nodes_shuffle.append(node)\n",
    "        batch_minus_ego = list(set(batch) - {node}) #  - set(list(g[node])))\n",
    "        for _ in range(n_neg_samples_rand):\n",
    "            neg_nodes_rand.append(\n",
    "                random.choice(\n",
    "                    batch_minus_ego\n",
    "                )\n",
    "            )\n",
    "    if len(neg_nodes_shuffle) > 0 and len(neg_nodes_rand) > 0:\n",
    "        emb_neg1 = model2(neg_nodes_shuffle, randomize_features=True)\n",
    "        emb_neg2 = model2(neg_nodes_rand, randomize_features=False)\n",
    "        total_neg_samples = n_neg_samples_rand + n_neg_samples_shuffle\n",
    "        emb_neg = torch.cat((emb_neg1, emb_neg2), dim=1).view(\n",
    "            total_neg_samples * len(batch),\n",
    "            -1,\n",
    "        )\n",
    "    elif len(neg_nodes_shuffle) > 0 and len(neg_nodes_rand) == 0:\n",
    "        emb_neg = model2(neg_nodes_shuffle, randomize_features=True)\n",
    "    elif len(neg_nodes_shuffle) == 0 and len(neg_nodes_rand) > 0:\n",
    "        emb_neg = model2(neg_nodes_rand, randomize_features=False)\n",
    "    pos_weight = emb_neg.numel() / emb_u.numel()\n",
    "    loss = sigmoid_loss(emb_u, emb_v, emb_neg, pos_weight)\n",
    "    total_loss += float(loss.cpu().data.numpy())\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "model1 = model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [x for x in g.node]\n",
    "\n",
    "emb_list = []\n",
    "\n",
    "for node in node_list:\n",
    "    emb_list.append(model1([node]).cpu().data.numpy().tolist()[0])\n",
    "\n",
    "emb = np.array(emb_list)\n",
    "    \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "df = pd.DataFrame(TSNE(n_components=2).fit_transform(emb))\n",
    "\n",
    "df['label'] = [labels[x] for x in node_list]\n",
    "\n",
    "df.columns = ['x', 'y', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.lmplot(\n",
    "    x='x',\n",
    "    y='y',\n",
    "    data=df,\n",
    "    fit_reg=False,\n",
    "    hue='label',\n",
    "    legend=False,\n",
    "    height=10,\n",
    "    aspect=1.5,\n",
    "    scatter_kws={\"s\": 50},\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(df[['x', 'y']], [labels[x] for x in node_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
